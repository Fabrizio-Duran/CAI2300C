{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND/noygCl5+3o7qwHxB+Z7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabrizio-Duran/CAI2300C/blob/main/Assignment_2_Complete_CAI2300C_Fabrizio_Duran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VmBcpkn3Pem2"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import userdata\n",
        "openai = userdata.get('OpenAIAPI')\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key = OpenAIAPI)  # Replace with your actual OpenAI API key\n",
        "\n",
        "# Define the embedding function\n",
        "def create_embeddings(texts, model=\"text-embedding-3-small\"):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        response = client.embeddings.create(\n",
        "            input=text,\n",
        "            model=model\n",
        "        )\n",
        "        embeddings.append(response.data[0].embedding)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample product reviews dataset\n",
        "product_reviews = [\n",
        "    \"This laptop has an amazing battery life and the performance is top-notch!\",\n",
        "    \"The phone camera quality is very poor, and the battery drains quickly.\",\n",
        "    \"I love this vacuum cleaner! It’s lightweight and very efficient.\",\n",
        "    \"Terrible customer service. I waited weeks for a replacement and got no response.\",\n",
        "    \"The headphones have great sound quality but are uncomfortable to wear for long periods.\",\n",
        "    \"The smartwatch is feature-packed, but the user interface is not intuitive.\",\n",
        "    \"I regret buying this washing machine. It makes a lot of noise and doesn’t clean properly.\",\n",
        "    \"This gaming mouse is super responsive and has great customization options.\",\n",
        "    \"The blender works well, but it is extremely loud!\",\n",
        "    \"The shoes are stylish but not comfortable for long walks.\"\n",
        "]"
      ],
      "metadata": {
        "id": "OUiqxOHNQGB8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for product reviews\n",
        "reviews = []\n",
        "embeddings = create_embeddings(product_reviews, model=\"text-embedding-3-small\")\n",
        "\n",
        "for review, embedding in zip(product_reviews, embeddings):\n",
        "    reviews.append({\"review\": review, \"embedding\": embedding})"
      ],
      "metadata": {
        "id": "yMpRaQuiQIaU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search query\n",
        "search_text = \"Which laptop has good battery life?\"\n",
        "\n",
        "# Generate the embedding for the query\n",
        "search_embedding = create_embeddings([search_text])[0]\n",
        "\n",
        "# Calculate cosine distances between the query and reviews\n",
        "distances = []\n",
        "for review in reviews:\n",
        "    dist = distance.cosine(search_embedding, review[\"embedding\"])\n",
        "    distances.append(dist)\n",
        "\n",
        "# Find the closest review\n",
        "min_dist_ind = np.argmin(distances)\n",
        "closest_review = reviews[min_dist_ind]\n",
        "\n",
        "print(f\"Search Query: {search_text}\")\n",
        "print(f\"Closest Review: {closest_review['review']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwByjUyFQUIc",
        "outputId": "c8f856c5-d20c-4d19-9b8a-ba468d2b2b27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Query: Which laptop has good battery life?\n",
            "Closest Review: This laptop has an amazing battery life and the performance is top-notch!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -qqq\n",
        "import gradio as gr\n",
        "\n",
        "# Define the search function\n",
        "def find_similar_review(query):\n",
        "    search_embedding = create_embeddings([query])[0]\n",
        "    distances = [distance.cosine(search_embedding, r[\"embedding\"]) for r in reviews]\n",
        "    min_dist_ind = np.argmin(distances)\n",
        "    closest_review = reviews[min_dist_ind]\n",
        "    return f\"Query: {query}\\n\\nMost Similar Review: {closest_review['review']}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=find_similar_review,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Semantic Search for Product Reviews\",\n",
        "    description=\"Enter a product-related query to find similar reviews in the database.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "2G9eIp4WQZCj",
        "outputId": "2f28ed17-dcf4-46a5-b06c-34fe91e2347d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRunning Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ddb2a01224267ae50c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ddb2a01224267ae50c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}